\begin{abstract}
Multi-Agent Artificial Intelligence systems, composed of coordinated AI agents, increasingly automate complex knowledge work~\citep{Allmendinger_2025_MAAI}. While fairness challenges in analytical artificial intelligence are well documented~\citep{DeArteaga_2022_Algorithmic_Fairness}, fairness in Multi-Agent Artificial Intelligence systems remains unexplored~\citep{Allmendinger_2025_MAAI_Fairness_Unpublished}. Four critical research gaps have been identified~\citep{Allmendinger_2025_MAAI_Fairness_Unpublished}: the exclusion of human participants beyond system design, reliance on homogeneous foundation models, unexplored system dynamics including manipulation vulnerabilities, and exclusive focus on English as input language.

This thesis addresses these gaps by replicating the fairness experiments of \citet{Frohlich_Oppenheimer_1992_Book}, originally conducted with human participants, using multiple artificial intelligence agents. The experimental design, rooted in Rawlsian philosophy, asks participants to select one of four distributive justice principles that determine income distribution in a hypothetical society without knowing their future class position.

The findings reveal significant differences between AI and human groups. While both favor the same principle in the majority of cases, AI groups concentrate more heavily on this choice (90.9\% vs. 79.4\% for humans), whereas human groups exhibit greater variance. The origin of the underlying large language model significantly affects outcomes, with American models exhibiting more egalitarian preferences than Chinese models. Intelligence asymmetries create manipulation vulnerabilities: high-capability agents reshape consensus in 33\% of experiments compared to 3\% for low-capability agents. Language selection produces measurable effects on both consensus formation and outcome variance.

This thesis provides an initial empirical investigation of fairness in Multi-Agent Artificial Intelligence systems and offers evidence to address the presented research gaps, while raising further research questions that inform practitioners on the consequences of their design choices. 
\end{abstract}

